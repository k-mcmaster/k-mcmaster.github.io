{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f50a2c95-610f-480f-9c17-4acfd2669c8d",
   "metadata": {},
   "source": [
    "# <center>An Analysis of Transformative Works Created by Fans of the Harry Potter Series in Reaction to the Author's Public Political Comments</center>\n",
    "\n",
    "## <center>Project completed by Kymberlee McMaster on May 16th, 2022</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cb7072-0ffe-4d1a-ad3c-08f3333a4b91",
   "metadata": {},
   "source": [
    "### <center>Introduction</center>\n",
    "\n",
    "Fans are often known for using their talents and dedication to create new media based on the things they enjoy. One of the best examples of this is the writing and reading of fanfiction, the practice in which amateur authors may take aspects from the original content that they enjoyed and transforming them into original works of their own creation. There are various methods that these authors use to share their works with other individuals who also enjoyed the original piece of media but one of the most common is to post the work to a dedicated site for the posting and reading of fanfiction. While there are quite a few options available, we'll be focusing on Archive of Our Own, known colloquially as AO3, for our purposes as AO3's built in tagging and data storage system will allow us to search through the works of fiction using the author's own tags for their work rather than attempting to create tags ourself. \n",
    "\n",
    "However, since AO3 currently has over nine million works, in order to better analyze the data associated with the site and trends of fanfiction authors, we'll be focusing on writings by fans of a specific piece of media: the Harry Potter series written by J.K. Rowling.[[1]](https://archiveofourown.org/works/search?work_search%5Bquery%5D=) Additionally, we'll be specifically be focusing on the fanfiction written around a specific date in time as there are over 300,000 works for that series alone. \n",
    "\n",
    "On June 6th of 2020, author J.K. Rowling took to Twitter to express her displeasure over the use of the phrase \"people who menstruate\" rather than the word women.[[2]](https://www.glamour.com/story/a-complete-breakdown-of-the-jk-rowling-transgender-comments-controversy) This tweet and the subsequent tweets that followed it came under a lot of backlash with trans activists and fans of the Harry Potter series. This was not the first time that author J.K. Rowling had expressed such views and received backlash, but it is one of the most notable, so we will be analyzing works of fanfiction posted onto AO3 for the two weeks before the tweet was made and the two weeks following the tweet to view the potential impact that Rowling's postings may have had on the writings of the LGBTQIA+ community members and their allies. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc6daf-37e7-4d50-90de-6428eba682e3",
   "metadata": {},
   "source": [
    "<b>An Important Note:</b> Content posted on AO3, while subject to AO3's terms of service, is not policed for the actual content itself. AO3's dedication to protect the authors who post on their site means that content posted to the site can contain a wide array of mature content, as most of their focus on author protection are centered around protecting the author from backlash by the original owners of the potentially trademarked intellectual property. Per their own site: \"The Archive does not prescreen for content. Complaints are investigated only when they are submitted through the appropriate channels and with the appropriate information.\"[[3]](https://archiveofourown.org/tos#content) Users are expected to police their own media consumption through the use of the built-in tagging system. This means that some of the information we collect about fics for this project may mention or allude to mature themes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1b77fe-964f-44f7-8be8-e39bc29909aa",
   "metadata": {},
   "source": [
    "### <center>Data Collection</center>\n",
    "\n",
    "As AO3 does not have a built in API, we will need to build our own method of scraping the data found on the site. In order to collect the data and avoid unneccesary scraping we'll be using AO3's built in search function to pre-search for works that were created between our dates of interest: May 23rd,2020 and June 19th, 2020. We do this by accessing the Works Search page located [here](https://archiveofourown.org/works/search), and entering our parameters into the Any Search field: created_at:[\"2020-05-23\" TO \"2020-06-19\"]. As well as selecting the English language option. This will generate the link that we can use in the data scraper that will gather the information about the works for us, located [here](https://archiveofourown.org/works/search?commit=Search&page=1&work_search[bookmarks_count]=&work_search[character_names]=&work_search[comments_count]=&work_search[complete]=&work_search[creators]=&work_search[crossover]=&work_search[fandom_names]=Harry+Potter+-+J.+K.+Rowling&work_search[freeform_names]=&work_search[hits]=&work_search[kudos_count]=&work_search[language_id]=en&work_search[query]=created_at%3A[%222020-05-23%22+TO+%222020-06-19%22]&work_search[rating_ids]=&work_search[relationship_names]=&work_search[revised_at]=&work_search[single_chapter]=0&work_search[sort_column]=created_at&work_search[sort_direction]=asc&work_search[title]=&work_search[word_count]=). \n",
    "\n",
    "By looking at our search results, we will see that we will be scraping the information about 3,523 works that were created and area available publicly without an account in the month time period we've identified. Below, we will first import the libararies necessary for this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6ef4c48-3b62-48a0-b4bc-0de6f8efaff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries necessary to complete this project \n",
    "import requests\n",
    "import math\n",
    "from bs4 import BeautifulSoup \n",
    "import csv\n",
    "import re \n",
    "import random\n",
    "import time\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from datetime import datetime \n",
    "\n",
    "\n",
    "import json \n",
    "import os.path \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89e8103-a34c-4a85-8993-3fc7127a650c",
   "metadata": {},
   "source": [
    "With our libaries imported, we can start off by initializing some of the necessary variables and setting up the CSV file we will be using to temporarily store all of this data. We know that there are 3,523 works to be consumed, and there are 20 works displayed on each search page so we'll need to request the informtion from 177 pages. We split the URL into parts before and after the page number is stored to that we can complete our requests through an iterative process which automatically updates the page number used to request data. Then we initialize a new files to store the content from the scraping as we'll be completing it in page portions and that would make it difficult to store as a pandas dataframe right off the bat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b645645a-3f04-4eb3-9936-42e3ac15bffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the URL into parts and store the current page number with those parts \n",
    "urlpt1 = \"https://archiveofourown.org/works/search?commit=Search&page=\"\n",
    "currpagenum = 1\n",
    "urlpt2 = \"&work_search[bookmarks_count]=&work_search[character_names]=&work_search[comments_count]=&work_search[complete]=&work_search[creators]=&work_search[crossover]=&work_search[fandom_names]=Harry+Potter+-+J.+K.+Rowling&work_search[freeform_names]=&work_search[hits]=&work_search[kudos_count]=&work_search[language_id]=en&work_search[query]=created_at%3A[%222020-05-23%22+TO+%222020-06-19%22]&work_search[rating_ids]=&work_search[relationship_names]=&work_search[revised_at]=&work_search[single_chapter]=0&work_search[sort_column]=created_at&work_search[sort_direction]=asc&work_search[title]=&work_search[word_count]=\"\n",
    "\n",
    "#Identified the number of works and pages that the scraper will need to iterate through\n",
    "works = 3523\n",
    "pages = math.ceil(works/20)\n",
    "\n",
    "#Iniate a new file to store the basic content from the scraping \n",
    "header = ['Title', 'Author', 'ID', 'Date_updated', 'Rating', 'Pairing', 'Warning', 'Complete', 'Language', 'Word_count', 'Num_chapters', 'Num_comments', 'Num_kudos', 'Num_bookmarks', 'Num_hits', 'Tags', 'Summary']\n",
    "with open('storedbasic.csv','w', encoding='utf8') as storedbasic:\n",
    "    writer = csv.writer(storedbasic)\n",
    "    writer.writerow(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76b8e33-ef19-4dd5-8b3a-b256603d9318",
   "metadata": {},
   "source": [
    "Now that we've completed some of our basic work, we can begin to design some of the functions we'll need to call to scrape the data out of the page. First, we have inspect the page to see how the data on each page is stored. By using the developers tools, we can see that the results of the search are displayed in a class identified as a “works index group\" and each work is a list item below that with the role \"article\". \n",
    "\n",
    "<center><b>Page Inspection Using Web Developer Tools</b></center>\n",
    "<center><img src=\"PageInspect.png\"></center>\n",
    "\n",
    "\n",
    "We'll use that information to define our helper function that will take the BeautifulSoup from a page, add the relevant information about the work to various lists and then store those lists into the CSV file that we previously initialized. \n",
    "\n",
    "There are a couple interesting things to note here about the information we are choosing to gather. AO3 has built in site protections that displays a simple Retry Later if too many requests are being made to the site by one person at a time. As such, we are only scraping the information that is available from the works search page since that means we only search the number of pages in the search results rather than gathering the content that is available on the works' pages themselves. One such example of information that could have been gathered from the works' pages is the comments associated with the work. AO3 allows for author-specific comments sections in which the author of the work can choose whether or not to allow comments and if they are allowing comments, whether those comments need to come from someone who holds an account with the site itself. While these comments could have had some interested information for us to take a look at, we area already dealing with an extremely large amount of data and the scraping of the comments section would have required that we scrape each individual webpage for the 3,523 different works that we have gathered data on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d49c95-6902-4238-bdf4-ddc7f784cb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Function to gather all data \n",
    "def basicdata(mysoup): \n",
    "    #Initialize a set of variables to store all titles and info for page to add to the CSV all at once \n",
    "    titles = []\n",
    "    authors = []\n",
    "    ids = []\n",
    "    date_updated = []\n",
    "    ratings = []\n",
    "    pairings = []\n",
    "    warnings = []\n",
    "    complete = []\n",
    "    languages = []\n",
    "    word_count = []\n",
    "    chapters = []\n",
    "    comments = []\n",
    "    kudos = []\n",
    "    bookmarks = []\n",
    "    hits = []\n",
    "    tags = []\n",
    "    summary = []\n",
    "    \n",
    "    for article in mysoup.find_all('li', {'role':'article'}):\n",
    "        titles.append(article.find('h4', {'class':'heading'}).find('a').text)\n",
    "        try:\n",
    "            authors.append(article.find('a', {'rel':'author'}).text)\n",
    "        except:\n",
    "            authors.append('Anonymous')\n",
    "        ids.append(article.find('h4', {'class':'heading'}).find('a').get('href')[7:])\n",
    "        date_updated.append(article.find('p', {'class':'datetime'}).text)\n",
    "        ratings.append(article.find('span', {'class':re.compile(r'rating\\-.*rating')}).text)\n",
    "        pairings.append(article.find('span', {'class':re.compile(r'category\\-.*category')}).text)\n",
    "        warnings.append(article.find('span', {'class':re.compile(r'warning\\-.*warnings')}).text)\n",
    "        complete.append(article.find('span', {'class':re.compile(r'complete\\-.*iswip')}).text)\n",
    "        languages.append(article.find('dd', {'class':'language'}).text)\n",
    "        tags.append(article.find('ul', {'class':'tags commas'}).text)\n",
    "        count = article.find('dd', {'class':'words'}).text\n",
    "        if len(count) > 0:\n",
    "            word_count.append(count)\n",
    "        else:\n",
    "            word_count.append('0')\n",
    "        chapters.append(article.find('dd', {'class':'chapters'}).text.split('/')[0])\n",
    "        try:\n",
    "            comments.append(article.find('dd', {'class':'comments'}).text)\n",
    "        except:\n",
    "            comments.append('0')\n",
    "        try:\n",
    "            kudos.append(article.find('dd', {'class':'kudos'}).text)\n",
    "        except:\n",
    "            kudos.append('0')\n",
    "        try:\n",
    "            bookmarks.append(article.find('dd', {'class':'bookmarks'}).text)\n",
    "        except:\n",
    "            bookmarks.append('0')\n",
    "        try:\n",
    "            hits.append(article.find('dd', {'class':'hits'}).text)\n",
    "        except:\n",
    "            hits.append('0')\n",
    "        #try: \n",
    "            #tags.append(article.find('span', {'class':re.compile(r'freeforms\\-.*freeforms')}).text)\n",
    "        #except: \n",
    "            #tags.append(' ')\n",
    "        try:\n",
    "            summary.append(article.find('blockquote', {'class':'userstuff summary'}).text)\n",
    "        except: \n",
    "            summary.append(' ')\n",
    "            \n",
    "            \n",
    "    df = pd.DataFrame(list(zip(titles, authors, ids, date_updated, ratings, pairings,\\\n",
    "                              warnings, complete, languages, word_count, chapters,\\\n",
    "                               comments, kudos, bookmarks, hits, tags, summary)))\n",
    "    \n",
    "    with open('storedbasic.csv','a', encoding='utf8') as storedbasic:\n",
    "        df.to_csv(storedbasic, header=False, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1870da39-bc14-4c6c-991d-8f84693fe196",
   "metadata": {},
   "source": [
    "With our helper function for our basic data, we can now  iterate through the pages of the searched works and gather the basic data into the CSV files previously created. As previously stated, due to AO3's built in site protections, we will scrape by increments of pages and pause between each set of pages in order to ensure that we can gather all of the data we are trying to request from the site. For our purposes, we will be using an increment of 100 pages as it was a nice round number that was regularly accepted by the site and then a pause time of 10 minutes so that enough time had elapsed after our previous round that it would accept the next round of 100 pages being requested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed1a862a-4514-4178-8b0d-a39f8b45c368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking a break from parsing. Current page count is: 100\n",
      "Will resume in 10 min\n",
      "Wait time is over, will resume parsing now.\n",
      "Parsing has finished, the remainder of basic data has been consumed\n"
     ]
    }
   ],
   "source": [
    "#Reset page number in case anything has gotten messed up with the block\n",
    "currpagenum = 1\n",
    "\n",
    "#Set the page by using the page number, and the URL parts\n",
    "page = requests.get(urlpt1 + str(currpagenum) + urlpt2)\n",
    "\n",
    "#Use BeautifulSoup to parse the data as html\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "#This for loop will iterate through the pages and add the basic data to the basic data table \n",
    "for i in range(1, pages + 1): \n",
    "    \n",
    "    url = urlpt1 + str(currpagenum) + urlpt2 \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "    basicdata(soup) \n",
    "    \n",
    "    currpagenum += 1\n",
    "    \n",
    "    if (i % 100) == 0 : \n",
    "        print(\"Taking a break from parsing. Current page count is: \" + str(currpagenum - 1) )\n",
    "        print(\"Will resume in 10 min\")\n",
    "        time.sleep(600)\n",
    "        print(\"Wait time is over, will resume parsing now.\")\n",
    "    \n",
    "print(\"Parsing has finished, the remainder of basic data has been consumed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7ead2c-5f42-4736-b382-85c17e531ed3",
   "metadata": {},
   "source": [
    "The output of the page parsing into the CSV files is several print statements that just allow us to view where our current parsing status is, as we have a 10 minute break included in our parsing so we want to be able to know that everything is continuing to process and move along smoothly. \n",
    "\n",
    "With all of the data parsed into a CSV file, we can now use the built in pandas functionality to create a pandas dataframe that we can use to manipulate our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "872344c6-4c1e-4ddb-80b5-a399d07de9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>ID</th>\n",
       "      <th>Date_updated</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Pairing</th>\n",
       "      <th>Warning</th>\n",
       "      <th>Complete</th>\n",
       "      <th>Language</th>\n",
       "      <th>Word_count</th>\n",
       "      <th>Num_chapters</th>\n",
       "      <th>Num_comments</th>\n",
       "      <th>Num_kudos</th>\n",
       "      <th>Num_bookmarks</th>\n",
       "      <th>Num_hits</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This Love I Have Inside</td>\n",
       "      <td>stargazing_dreamer_girl</td>\n",
       "      <td>24329029</td>\n",
       "      <td>23 May 2020</td>\n",
       "      <td>General Audiences</td>\n",
       "      <td>F/M</td>\n",
       "      <td>No Archive Warnings Apply</td>\n",
       "      <td>Complete Work</td>\n",
       "      <td>English</td>\n",
       "      <td>9,403</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>612</td>\n",
       "      <td>\\nNo Archive Warnings ApplyFred Weasley/Origin...</td>\n",
       "      <td>\\nClara Comder, student at Hogwarts School of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spelling It Out</td>\n",
       "      <td>Nocturnal_Daydreams</td>\n",
       "      <td>24329044</td>\n",
       "      <td>23 May 2020</td>\n",
       "      <td>Not Rated</td>\n",
       "      <td>F/M, Other</td>\n",
       "      <td>Choose Not To Use Archive Warnings</td>\n",
       "      <td>Complete Work</td>\n",
       "      <td>English</td>\n",
       "      <td>29,407</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>213</td>\n",
       "      <td>32</td>\n",
       "      <td>5338</td>\n",
       "      <td>\\nCreator Chose Not To Use Archive WarningsHer...</td>\n",
       "      <td>\\nTattoos or Birthmarks of your soulmates firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Untamed Journey</td>\n",
       "      <td>Jetainia</td>\n",
       "      <td>24329050</td>\n",
       "      <td>23 May 2020</td>\n",
       "      <td>General Audiences</td>\n",
       "      <td>F/M</td>\n",
       "      <td>No Archive Warnings Apply</td>\n",
       "      <td>Complete Work</td>\n",
       "      <td>English</td>\n",
       "      <td>1,612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>\\nNo Archive Warnings ApplyHelga Hufflepuff/Sa...</td>\n",
       "      <td>\\nThe roaming Hogwarts saloon is a place of ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Quill</td>\n",
       "      <td>xslytherclawx</td>\n",
       "      <td>24329686</td>\n",
       "      <td>23 May 2020</td>\n",
       "      <td>Teen And Up Audiences</td>\n",
       "      <td>M/M</td>\n",
       "      <td>No Archive Warnings Apply</td>\n",
       "      <td>Complete Work</td>\n",
       "      <td>English</td>\n",
       "      <td>586</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>664</td>\n",
       "      <td>\\nNo Archive Warnings ApplyDraco Malfoy/Harry ...</td>\n",
       "      <td>\\nHarry's always wondered about Draco's golden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harry Potter Bending Force</td>\n",
       "      <td>Gman85</td>\n",
       "      <td>24329902</td>\n",
       "      <td>19 Jan 2022</td>\n",
       "      <td>Explicit</td>\n",
       "      <td>F/M</td>\n",
       "      <td>Underage</td>\n",
       "      <td>Work in Progress</td>\n",
       "      <td>English</td>\n",
       "      <td>128,631</td>\n",
       "      <td>17</td>\n",
       "      <td>104</td>\n",
       "      <td>286</td>\n",
       "      <td>133</td>\n",
       "      <td>21619</td>\n",
       "      <td>\\nUnderageOther Relationship Tags to Be Added ...</td>\n",
       "      <td>\\nHarry was woefully unprepared for the Tri-Wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>Ante Astra</td>\n",
       "      <td>Evandar</td>\n",
       "      <td>24812620</td>\n",
       "      <td>19 Jun 2020</td>\n",
       "      <td>Mature</td>\n",
       "      <td>M/M</td>\n",
       "      <td>Underage</td>\n",
       "      <td>Complete Work</td>\n",
       "      <td>English</td>\n",
       "      <td>3,126</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>825</td>\n",
       "      <td>67</td>\n",
       "      <td>7871</td>\n",
       "      <td>\\nUnderageRegulus Black/Sirius Black Alphard B...</td>\n",
       "      <td>\\nThe morning after the night before. Sirius i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>The Slytherin Scarf</td>\n",
       "      <td>FateRestarting</td>\n",
       "      <td>24812632</td>\n",
       "      <td>19 Jun 2020</td>\n",
       "      <td>Teen And Up Audiences</td>\n",
       "      <td>F/M</td>\n",
       "      <td>No Archive Warnings Apply</td>\n",
       "      <td>Complete Work</td>\n",
       "      <td>English</td>\n",
       "      <td>2,677</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>404</td>\n",
       "      <td>43</td>\n",
       "      <td>3622</td>\n",
       "      <td>\\nNo Archive Warnings ApplyHermione Granger/Dr...</td>\n",
       "      <td>\\nA prefect's round that ends in the usual arg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3520</th>\n",
       "      <td>Muggle Robbery</td>\n",
       "      <td>Axelle_Sof</td>\n",
       "      <td>24812779</td>\n",
       "      <td>19 Jun 2020</td>\n",
       "      <td>General Audiences</td>\n",
       "      <td>M/M</td>\n",
       "      <td>Choose Not To Use Archive Warnings</td>\n",
       "      <td>Complete Work</td>\n",
       "      <td>English</td>\n",
       "      <td>1,522</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>780</td>\n",
       "      <td>\\nCreator Chose Not To Use Archive WarningsDra...</td>\n",
       "      <td>\\nHarry and Draco go on a date. But not togeth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>Forged in Fire</td>\n",
       "      <td>torino10154</td>\n",
       "      <td>24812839</td>\n",
       "      <td>20 Jun 2020</td>\n",
       "      <td>Explicit</td>\n",
       "      <td>M/M</td>\n",
       "      <td>Rape/Non-Con, Underage</td>\n",
       "      <td>Complete Work</td>\n",
       "      <td>English</td>\n",
       "      <td>857</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>753</td>\n",
       "      <td>50</td>\n",
       "      <td>43553</td>\n",
       "      <td>\\nRape/Non-Con UnderageHarry Potter/Quirinus Q...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>Amortentia</td>\n",
       "      <td>Im_Chamsae</td>\n",
       "      <td>24813910</td>\n",
       "      <td>22 Jun 2020</td>\n",
       "      <td>General Audiences</td>\n",
       "      <td>F/M</td>\n",
       "      <td>No Archive Warnings Apply</td>\n",
       "      <td>Complete Work</td>\n",
       "      <td>English</td>\n",
       "      <td>4,249</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>95</td>\n",
       "      <td>7</td>\n",
       "      <td>932</td>\n",
       "      <td>\\nNo Archive Warnings ApplyStephanie Brown/Tim...</td>\n",
       "      <td>\\nWhat initially started out as an interest in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3523 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Title                   Author        ID  \\\n",
       "0        This Love I Have Inside  stargazing_dreamer_girl  24329029   \n",
       "1                Spelling It Out      Nocturnal_Daydreams  24329044   \n",
       "2                Untamed Journey                 Jetainia  24329050   \n",
       "3                      The Quill            xslytherclawx  24329686   \n",
       "4     Harry Potter Bending Force                   Gman85  24329902   \n",
       "...                          ...                      ...       ...   \n",
       "3518                  Ante Astra                  Evandar  24812620   \n",
       "3519         The Slytherin Scarf           FateRestarting  24812632   \n",
       "3520              Muggle Robbery               Axelle_Sof  24812779   \n",
       "3521              Forged in Fire              torino10154  24812839   \n",
       "3522                  Amortentia               Im_Chamsae  24813910   \n",
       "\n",
       "     Date_updated                 Rating     Pairing  \\\n",
       "0     23 May 2020      General Audiences         F/M   \n",
       "1     23 May 2020              Not Rated  F/M, Other   \n",
       "2     23 May 2020      General Audiences         F/M   \n",
       "3     23 May 2020  Teen And Up Audiences         M/M   \n",
       "4     19 Jan 2022               Explicit         F/M   \n",
       "...           ...                    ...         ...   \n",
       "3518  19 Jun 2020                 Mature         M/M   \n",
       "3519  19 Jun 2020  Teen And Up Audiences         F/M   \n",
       "3520  19 Jun 2020      General Audiences         M/M   \n",
       "3521  20 Jun 2020               Explicit         M/M   \n",
       "3522  22 Jun 2020      General Audiences         F/M   \n",
       "\n",
       "                                 Warning          Complete Language  \\\n",
       "0              No Archive Warnings Apply     Complete Work  English   \n",
       "1     Choose Not To Use Archive Warnings     Complete Work  English   \n",
       "2              No Archive Warnings Apply     Complete Work  English   \n",
       "3              No Archive Warnings Apply     Complete Work  English   \n",
       "4                               Underage  Work in Progress  English   \n",
       "...                                  ...               ...      ...   \n",
       "3518                            Underage     Complete Work  English   \n",
       "3519           No Archive Warnings Apply     Complete Work  English   \n",
       "3520  Choose Not To Use Archive Warnings     Complete Work  English   \n",
       "3521              Rape/Non-Con, Underage     Complete Work  English   \n",
       "3522           No Archive Warnings Apply     Complete Work  English   \n",
       "\n",
       "     Word_count  Num_chapters  Num_comments  Num_kudos  Num_bookmarks  \\\n",
       "0         9,403             1             0         37              1   \n",
       "1        29,407             1            14        213             32   \n",
       "2         1,612             1             0         17              1   \n",
       "3           586             1             4         68              2   \n",
       "4       128,631            17           104        286            133   \n",
       "...         ...           ...           ...        ...            ...   \n",
       "3518      3,126             1            38        825             67   \n",
       "3519      2,677             1            38        404             43   \n",
       "3520      1,522             1             0         43              3   \n",
       "3521        857             1            23        753             50   \n",
       "3522      4,249             1            10         95              7   \n",
       "\n",
       "      Num_hits                                               Tags  \\\n",
       "0          612  \\nNo Archive Warnings ApplyFred Weasley/Origin...   \n",
       "1         5338  \\nCreator Chose Not To Use Archive WarningsHer...   \n",
       "2          240  \\nNo Archive Warnings ApplyHelga Hufflepuff/Sa...   \n",
       "3          664  \\nNo Archive Warnings ApplyDraco Malfoy/Harry ...   \n",
       "4        21619  \\nUnderageOther Relationship Tags to Be Added ...   \n",
       "...        ...                                                ...   \n",
       "3518      7871  \\nUnderageRegulus Black/Sirius Black Alphard B...   \n",
       "3519      3622  \\nNo Archive Warnings ApplyHermione Granger/Dr...   \n",
       "3520       780  \\nCreator Chose Not To Use Archive WarningsDra...   \n",
       "3521     43553  \\nRape/Non-Con UnderageHarry Potter/Quirinus Q...   \n",
       "3522       932  \\nNo Archive Warnings ApplyStephanie Brown/Tim...   \n",
       "\n",
       "                                                Summary  \n",
       "0     \\nClara Comder, student at Hogwarts School of ...  \n",
       "1     \\nTattoos or Birthmarks of your soulmates firs...  \n",
       "2     \\nThe roaming Hogwarts saloon is a place of ha...  \n",
       "3     \\nHarry's always wondered about Draco's golden...  \n",
       "4     \\nHarry was woefully unprepared for the Tri-Wi...  \n",
       "...                                                 ...  \n",
       "3518  \\nThe morning after the night before. Sirius i...  \n",
       "3519  \\nA prefect's round that ends in the usual arg...  \n",
       "3520  \\nHarry and Draco go on a date. But not togeth...  \n",
       "3521                                                     \n",
       "3522  \\nWhat initially started out as an interest in...  \n",
       "\n",
       "[3523 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Use read_csv to read the data stored in the CSV files into pandas dataframes\n",
    "AO3 = pd.read_csv(\"storedbasic.csv\")\n",
    "\n",
    "#Display the final dataframe\n",
    "display(AO3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac95180-ffe4-40c0-9bdc-831fd3ae4d7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <center>Data Processing</center>\n",
    "\n",
    "We now have a singular data frame, that contains all relevant information about fanfiction works that were created between May 23rd, 2020, and June 19th, 2020. However, this is the raw data so we want to first check that our dataframe is storing the data as the correct types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "992194f1-5528-4c1c-b332-bac3ce470363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title            object\n",
       "Author           object\n",
       "ID                int64\n",
       "Date_updated     object\n",
       "Rating           object\n",
       "Pairing          object\n",
       "Warning          object\n",
       "Complete         object\n",
       "Language         object\n",
       "Word_count       object\n",
       "Num_chapters      int64\n",
       "Num_comments      int64\n",
       "Num_kudos         int64\n",
       "Num_bookmarks     int64\n",
       "Num_hits          int64\n",
       "Tags             object\n",
       "Summary          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display the data frame columns with their associated types\n",
    "AO3.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fba186-e27c-4513-a0f7-8b609aa86661",
   "metadata": {},
   "source": [
    "As we see above, while most of the data is properly stored: integers are all stored as int64 types and strings stored are objects, one column is not with Date_Updated being stored as a string object rather than a date type. Below we update the dataframe so that Date_Updated is stored correctly and we will be able to properly use it for our data analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e626935d-a880-440d-8f4b-5ac92acdf0cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                    object\n",
       "Author                   object\n",
       "ID                        int64\n",
       "Date_updated     datetime64[ns]\n",
       "Rating                   object\n",
       "Pairing                  object\n",
       "Warning                  object\n",
       "Complete                 object\n",
       "Language                 object\n",
       "Word_count               object\n",
       "Num_chapters              int64\n",
       "Num_comments              int64\n",
       "Num_kudos                 int64\n",
       "Num_bookmarks             int64\n",
       "Num_hits                  int64\n",
       "Tags                     object\n",
       "Summary                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Update the dataframe so that Date_Updated is properly stored as a datetime object \n",
    "AO3['Date_updated']= pd.to_datetime(AO3['Date_updated'])\n",
    "\n",
    "#Display the updated types of the dataframe\n",
    "AO3.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea0b82e-e87c-4e6b-94dc-f937c8b9d527",
   "metadata": {},
   "source": [
    "Returning to our original purpose, we want to see how Rowling's tweets may have impacted the posting of fans of her works who belong to the LGBTQIA+ community. As AO3 contains transformative works, and the original source material does not contain any LGBTQIA+ representation, the best way to view any potential impact is by identifying if a change occurred in the number of fanfiction works posted with LGBTQIA+ content. Especially since authors may have posted retaliatory works in which they transformed one or more of the canon characters within the work to be queer. Below shows one such example in which AO3 author, ughdotcom, posted a work and specified in their notes that the work was posted as a response to something JK Rowling had previously expressed. [[4]](https://archiveofourown.org/works/22817488)\n",
    "\n",
    "<center><b>ughdotcom's Anti Terf Posting</b></center>\n",
    "<center><img src=\"ughdotcom.png\"></center>\n",
    "\n",
    "\n",
    "Therefore, in order to best analyze potential responses by fanfiction authors, we will search for the occurrence of various queer identities and flag their presence within the tags so that we can use those flags to identify rates of posting. As seen above, the tags may contain markers before canon character names that indicate an update to something about this character, in this particular work, the character Hermione Granger is trans and Luna Lovegood is genderqueer. \n",
    "\n",
    "As gender and sexual identity expression is constantly changing and evolving, we will attempt to flag for most major sexual and gender identities, but there is the possibility that we may miss some. Our flags will center around the following groups who are members of the LGBTQIA+ community: lesbian, gay, bisexual, trans, nonbinary, queer, intersex, asexual, agender, and aromantic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64cca9ec-3960-44ee-bfec-c93fc88ae8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flag for presence of Lesbian\n",
    "\n",
    "\n",
    "#Flag for presence of Gay \n",
    "\n",
    "\n",
    "#Flag for presence of Bisexual \n",
    "\n",
    "\n",
    "#Flag for presence of Trans \n",
    "\n",
    "\n",
    "#Flag for presence of Nonbinary\n",
    "\n",
    "\n",
    "#Flag for presence of Queer \n",
    "\n",
    "\n",
    "#Flag for presence of Intersex \n",
    "\n",
    "\n",
    "#Flag for presence of Asexual \n",
    "\n",
    "\n",
    "#Flag for presence of Agender \n",
    "\n",
    "\n",
    "#Flag for presence of Aromantic "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63034d8-1b40-4b24-a77b-76c690f0ac7b",
   "metadata": {},
   "source": [
    "### <center>Exploratory Data Analysis</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c142a931-4f13-4733-acb6-52d025327d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d154d52a-ab4e-4f2e-9e16-a28206a9b440",
   "metadata": {},
   "source": [
    "### <center>Hypothesis Testing</center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e29670-cf1c-4808-a033-bb4b347ad92a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64ac3632-0c14-422f-ad24-a81dc603eb04",
   "metadata": {},
   "source": [
    "### <center>Conclusions</center>\n",
    "\n",
    "We now have a singular data frame "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
